{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA C"
      ],
      "metadata": {
        "id": "gHEavffp_GwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDlFrD7A_HUu",
        "outputId": "acf602bc-3f9b-4103-da26-246c4c2f3b46"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFMyri1z-SzU",
        "outputId": "af71e4d3-e8d1-4e91-8178-76b252473c0c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 26 19:54:30 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiplication Matrix"
      ],
      "metadata": {
        "id": "LdexS0SE-x5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mul_vectors.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#define BLOCK_SIZE 16\n",
        "using namespace std;\n",
        "\n",
        "void print_matrix(int *array, int rows, int cols) {\n",
        "    for (int i = 0; i < rows; i++) {\n",
        "        for (int j = 0; j < cols; j++) {\n",
        "            cout << array[i * cols + j] << \" \";\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void mul(int *a, int *b, int*c, int c_rows, int c_cols, int common){\n",
        "int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "int col = blockIdx.x  * blockDim.x + threadIdx.x;\n",
        "int sum = 0;\n",
        "\n",
        "if (col<c_cols && row<c_rows){\n",
        "for (int j = 0; j<common;j++){\n",
        "sum+=a[row*common + j]*b[j*c_cols + col];\n",
        "}\n",
        "c[c_cols*row + col] = sum;\n",
        "}\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "// initialize\n",
        "\n",
        "const int A_r = 3;\n",
        "const int A_c = 3;\n",
        "const int B_r = A_c;\n",
        "const int B_c = A_r;\n",
        "const int C_r = A_r;\n",
        "const int C_c = B_c;\n",
        "\n",
        "const int A_size = A_r*A_c;\n",
        "const int B_size  = B_r*B_c;\n",
        "const int C_size = C_r*C_c;\n",
        "\n",
        "int A[A_size] = {1, 2, 3, 4, 5, 6, 7, 8, 9};\n",
        "int B[B_size] = {1, 2, 3, 4, 5, 6, 7, 8, 9};\n",
        "int C[C_size];\n",
        "\n",
        "int *m1, *m2,*result;\n",
        "\n",
        "// allocate\n",
        "cudaMallocManaged(&m1,A_size*sizeof(int));\n",
        "cudaMallocManaged(&m2,B_size*sizeof(int));\n",
        "cudaMallocManaged(&result,C_size*sizeof(int));\n",
        "\n",
        "//copy data\n",
        "cudaMemcpy(m1,A,A_size*sizeof(int),cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(m2,B,B_size*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "// configuration\n",
        "dim3 dimGrid((C_c + BLOCK_SIZE -1)/BLOCK_SIZE,(C_r+BLOCK_SIZE-1)/BLOCK_SIZE);\n",
        "dim3 dimBlock(BLOCK_SIZE,BLOCK_SIZE);\n",
        "\n",
        "mul<<<dimGrid,dimBlock>>>(m1,m2,result,C_r,C_c,A_c);\n",
        "cudaDeviceSynchronize();\n",
        "\n",
        "cudaMemcpy(C,result,C_size*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\n",
        "cout<<\"Result: \\n\";\n",
        "print_matrix(C, C_r, C_c);\n",
        "\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcycoPrT-UAL",
        "outputId": "8067014d-7626-4617-cab0-9aa051cc7662"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mul_vectors.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o mul_vectors mul_vectors.cu"
      ],
      "metadata": {
        "id": "U014EH7f-W6E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./mul_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlVpTEaQ-YnZ",
        "outputId": "2b33e342-defd-401d-fe34-eae3fdfb8ad1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: \n",
            "30 36 42 \n",
            "66 81 96 \n",
            "102 126 150 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Addition Vectors"
      ],
      "metadata": {
        "id": "13TRQZRU-2cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add_vectors.cu\n",
        "#define BLOCK_SIZE 10\n",
        "# include <cuda.h>\n",
        "# include <iostream>\n",
        "using namespace std;\n",
        "\n",
        "void print_array(int *arr, int size){\n",
        "for (int i=0;i<size;i++){\n",
        "\n",
        "cout<< arr[i] << \" \";\n",
        "}\n",
        "cout<< endl;\n",
        "}\n",
        "\n",
        "__global__ void add(int *arr1, int * arr2, int * result, int size){\n",
        "\n",
        "int block_id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "if (block_id < size){\n",
        "result[block_id] = arr1[block_id] + arr2[block_id];\n",
        "}\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\n",
        "//initialize\n",
        "int size = 10;\n",
        "int arr1_cpu[size] = {1,2,3,4,5,6,7,8,9,10};\n",
        "int arr2_cpu[size] = {10,9,8,7,6,5,4,3,2,1};\n",
        "int result_cpu[size];\n",
        "\n",
        "int *arr1_gpu, *arr2_gpu, *result_gpu;\n",
        "\n",
        "//allocate memory to gpu\n",
        "cudaMallocManaged(&arr1_gpu, size*sizeof(int));\n",
        "cudaMallocManaged(&arr2_gpu, size*sizeof(int));\n",
        "cudaMallocManaged(&result_gpu,size*sizeof(int));\n",
        "\n",
        "//copy data from cpu to gpu\n",
        "cudaMemcpy(arr1_gpu,arr1_cpu,size*sizeof(int),cudaMemcpyHostToDevice);\n",
        "cudaMemcpy(arr2_gpu,arr2_cpu,size*sizeof(int),cudaMemcpyHostToDevice);\n",
        "\n",
        "// Configuration for Execution\n",
        "dim3 dimGrid((size+BLOCK_SIZE-1)/BLOCK_SIZE);\n",
        "dim3 dimBlock(BLOCK_SIZE);\n",
        "\n",
        "//Launch Kernel\n",
        "add<<<dimGrid,dimBlock>>>(arr1_gpu,arr2_gpu,result_gpu,size);\n",
        "cudaDeviceSynchronize();\n",
        "\n",
        "// copy data from gpu to cpu\n",
        "cudaMemcpy(result_cpu,result_gpu,size*sizeof(int),cudaMemcpyDeviceToHost);\n",
        "\n",
        "cout<<\"GPU Result: \\n\";\n",
        "print_array(result_cpu,size);\n",
        "\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ZXtXoQ-2GD",
        "outputId": "d25737b9-befe-48e5-80d0-6b7b5701477e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add_vectors.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o add_vectors add_vectors.cu"
      ],
      "metadata": {
        "id": "MqKPUqfT-1mT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./add_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SbBZtZi-rt7",
        "outputId": "da59adac-7447-45f6-b7db-f719d9d76e17"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Result: \n",
            "11 11 11 11 11 11 11 11 11 11 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p22mSzcX_AIv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}